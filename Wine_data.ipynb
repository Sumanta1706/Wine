{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumanta1706/Wine/blob/main/Wine_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-jYc9Rq8lT"
      },
      "source": [
        "## How to predict wine-class (wine data) using a keras deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPqvJITprdvG",
        "outputId": "c1aef8cb-6a96-4bd0-8806-faf44d5e7de8"
      },
      "source": [
        "print(format('How to predict wine-class (wine data) using a keras deep learning model','*^88'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********How to predict wine-class (wine data) using a keras deep learning model*********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq3Ysj17rkMQ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV1soXmwv2BP"
      },
      "source": [
        "*Loading all the necessary libraries*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaLdcX4urqYL"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "#from keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Xj-Rger3TO"
      },
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "834zUhTiwKWP"
      },
      "source": [
        "*Setting up the parameters*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8l020Vr7Ir"
      },
      "source": [
        "NB_CLASSES = 3\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSE = 1\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3AlZAh9wb-n"
      },
      "source": [
        "*Loading the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-jwkD-Or_0z"
      },
      "source": [
        "iris = datasets.load_wine()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMF-JzJfwpAb"
      },
      "source": [
        "*Preprocess The X Data By Scaling*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJzcprYHsC_i",
        "outputId": "ffd158a9-c977-487c-ced5-482cf51148ac"
      },
      "source": [
        "sc = StandardScaler(with_mean=True, with_std=True)\n",
        "sc.fit(X_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9pTuW_uwur8"
      },
      "source": [
        "*Apply the scaler to the X training data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XMrXEbbsIQN"
      },
      "source": [
        "X_train_std = sc.transform(X_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7mkNK6ow5vP"
      },
      "source": [
        "*Apply the SAME scaler to the X test data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJpS6_iGsKYD"
      },
      "source": [
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5V7qSGwxAbX"
      },
      "source": [
        "Apply the same scaler to the X test dataset, and converting the class vectors to binary class metrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TEhy98xGTX"
      },
      "source": [
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test  = np_utils.to_categorical(y_test, NB_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v51Z93eyxi8B"
      },
      "source": [
        "###Setting up the deep learning model###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1H2gm9AsQ6F"
      },
      "source": [
        "accuracy = []\n",
        "#for OPTIMIZER in [SGD(), RMSprop(), Adam()]:\n",
        "for OPTIMIZER in [Adam()]: \n",
        "    for NB_EPOCH in [5]:\n",
        "        for N_Units_in_Multiple_Layers in [64, 128, 256]:\n",
        "            model = Sequential()\n",
        "            model.add(Dense(units = N_Units_in_Multiple_Layers, input_shape=(X_train.shape[1],), \n",
        "                            kernel_regularizer=l2())) \n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Dense(units = N_Units_in_Multiple_Layers, kernel_regularizer=l2()))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Dense(units = NB_CLASSES))\n",
        "            model.add(Activation('softmax'))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmFhQauisayc",
        "outputId": "772d04b2-f474-4a48-f16d-6d5ca5edec08"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 256)               3584      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 771       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 70,147\n",
            "Trainable params: 70,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGY4YaBsd3w"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCQhKgpcshVS",
        "outputId": "2802bf39-8456-4402-a741-672aacb24da0"
      },
      "source": [
        "  model.fit(X_train_std, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                      verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "            "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 3.8944 - accuracy: 0.5044 - val_loss: 3.7059 - val_accuracy: 0.6897\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6871 - accuracy: 0.6903 - val_loss: 3.5508 - val_accuracy: 0.8276\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5021 - accuracy: 0.8230 - val_loss: 3.4105 - val_accuracy: 0.9655\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.3381 - accuracy: 0.9558 - val_loss: 3.2840 - val_accuracy: 0.9655\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1938 - accuracy: 0.9735 - val_loss: 3.1692 - val_accuracy: 0.9310\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4dfb8a7690>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5n945L_sn_T",
        "outputId": "06d48735-3564-40f4-ceb8-dc58eddae752"
      },
      "source": [
        "score = model.evaluate(X_test_std, Y_test, verbose=VERBOSE)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1601 - accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OGHMpFQsq74",
        "outputId": "4d472da8-afd2-4719-a514-70349c4724d0"
      },
      "source": [
        "print()\n",
        "print('Optimizers: ', OPTIMIZER)\n",
        "print('Epoch Sizes: ', NB_EPOCH)            \n",
        "print('Neurons or Units: ', N_Units_in_Multiple_Layers)            \n",
        "print(\"Test score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "accuracy.append(score[1])\n",
        "print()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizers:  <keras.optimizer_v2.adam.Adam object at 0x7f4dff9c1050>\n",
            "Epoch Sizes:  5\n",
            "Neurons or Units:  256\n",
            "Test score: 3.1601178646087646\n",
            "Test accuracy: 0.9166666865348816\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "7wcmTk6RstX8",
        "outputId": "abcd4b51-b363-4d46-faf2-354b53e62834"
      },
      "source": [
        "print(accuracy)\n",
        "y = accuracy; N = len(y); x = range(N); width = 1./1.5;\n",
        "plt.ylim(0.75,1.1)\n",
        "plt.bar(x,y,width); plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9166666865348816]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR4UlEQVR4nO3cf4xdZ33n8fenNkl22QYMHlGwTWIqo8TVoqQ7NZWybbJLAyZVY4qQ6iDatEKy2CVUpeUPoyBSuUINK6TtVooS3JUVglRMmqrtCNxGIT/KrjbZelKCi105mXjZepyUTJtCd5eI4OS7f8wx3ExmfM/Yd+baT94v6WrOeZ7n3PmMPfrcM/fce1NVSJLa9SPjDiBJWlkWvSQ1zqKXpMZZ9JLUOItekhpn0UtS44YWfZJ9SZ5J8o0l5i9L8nCS7yX52IK57UmOJplJsntUoSVJ/fU5o78T2H6a+WeBXwc+MziYZA1wG/BuYCtwQ5KtZxZTknSmhhZ9VX2V+TJfav6ZqjoIfH/B1DZgpqqOVdXzwH5gx9mElSQt39oVvO8NwPGB/Vng7YstTLIL2AXw6le/+t9cdtllKxhLktrz6KOP/kNVTSw2t5JF31tV7QX2AkxOTtb09PSYE0nS+SXJ/15qbiVfdXMC2DSwv7EbkyStopUs+oPAliSbk1wA7ASmVvD7SZIWMfSpmyRfAK4B1ieZBW4BXgVQVXck+TFgGrgYeDHJbwBbq+qfk9wE3AusAfZV1eGV+TEkSUsZWvRVdcOQ+b9n/mmZxeYOAAfOLJokaRR8Z6wkNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWrc0KJPsi/JM0m+scR8kvx+kpkkh5L85MDcC0ke625TowwuSeqnzxn9ncD208y/G9jS3XYBtw/MPVdVV3S36884pSTpjA0t+qr6KvDsaZbsAO6qeY8Ar03yxlEFlCSdnVE8R78BOD6wP9uNAVyUZDrJI0nes9QdJNnVrZuem5sbQSRJ0ikrfTH2kqqaBN4P/F6SH19sUVXtrarJqpqcmJhY4UiS9MoyiqI/AWwa2N/YjVFVp74eAx4CrhzB95MkLcMoin4K+JXu1Tc/DXynqp5Osi7JhQBJ1gNXAUdG8P0kScuwdtiCJF8ArgHWJ5kFbgFeBVBVdwAHgOuAGeC7wK91h14OfDbJi8w/oNxaVRa9JK2yoUVfVTcMmS/gw4uM/w/gX595NEnSKPjOWElqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1LihRZ9kX5Jnknxjifkk+f0kM0kOJfnJgbkbkzzR3W4cZXBJUj99zujvBLafZv7dwJbutgu4HSDJ64BbgLcD24Bbkqw7m7CSpOUbWvRV9VXg2dMs2QHcVfMeAV6b5I3Au4D7qurZqvon4D5O/4AhSVoBo3iOfgNwfGB/thtbavxlkuxKMp1kem5ubgSRJEmnnBMXY6tqb1VNVtXkxMTEuONIUlNGUfQngE0D+xu7saXGJUmraBRFPwX8Svfqm58GvlNVTwP3Au9Msq67CPvObkyStIrWDluQ5AvANcD6JLPMv5LmVQBVdQdwALgOmAG+C/xaN/dskt8BDnZ3taeqTndRV5K0AoYWfVXdMGS+gA8vMbcP2Hdm0SRJo3BOXIyVJK0ci16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcb2KPsn2JEeTzCTZvcj8JUnuT3IoyUNJNg7MvZDkse42NcrwkqTh1g5bkGQNcBtwLTALHEwyVVVHBpZ9Brirqj6X5N8Dvwv8cjf3XFVdMeLckqSe+pzRbwNmqupYVT0P7Ad2LFizFXig235wkXlJ0pj0KfoNwPGB/dlubNDXgfd2278I/GiS13f7FyWZTvJIkvecVVpJ0rKN6mLsx4Crk3wNuBo4AbzQzV1SVZPA+4HfS/LjCw9Osqt7MJiem5sbUSRJEvQr+hPApoH9jd3YD1TVU1X13qq6Eri5G/t29/VE9/UY8BBw5cJvUFV7q2qyqiYnJibO5OeQJC2hT9EfBLYk2ZzkAmAn8JJXzyRZn+TUfX0c2NeNr0ty4ak1wFXA4EVcSdIKG1r0VXUSuAm4F/hb4O6qOpxkT5Lru2XXAEeTPA68AfhUN345MJ3k68xfpL11wat1JEkrLFU17gwvMTk5WdPT0+OOIUnnlSSPdtdDX8Z3xkpS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktS4teMOMGqX7v7yuCNI0hn55q0/vyL36xm9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJalyvok+yPcnRJDNJdi8yf0mS+5McSvJQko0DczcmeaK73TjK8JKk4YYWfZI1wG3Au4GtwA1Jti5Y9hngrqp6G7AH+N3u2NcBtwBvB7YBtyRZN7r4kqRh+pzRbwNmqupYVT0P7Ad2LFizFXig235wYP5dwH1V9WxV/RNwH7D97GNLkvrqU/QbgOMD+7Pd2KCvA+/ttn8R+NEkr+95rCRpBY3qYuzHgKuTfA24GjgBvND34CS7kkwnmZ6bmxtRJEkS9Cv6E8Cmgf2N3dgPVNVTVfXeqroSuLkb+3afY7u1e6tqsqomJyYmlvkjSJJOp0/RHwS2JNmc5AJgJzA1uCDJ+iSn7uvjwL5u+17gnUnWdRdh39mNSZJWydCir6qTwE3MF/TfAndX1eEke5Jc3y27Bjia5HHgDcCnumOfBX6H+QeLg8CebkyStEp6fUxxVR0ADiwY++TA9j3APUscu48fnuFLklaZ74yVpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXG9ij7J9iRHk8wk2b3I/JuTPJjka0kOJbmuG780yXNJHutud4z6B5Aknd7aYQuSrAFuA64FZoGDSaaq6sjAsk8Ad1fV7Um2AgeAS7u5J6vqitHGliT11eeMfhswU1XHqup5YD+wY8GaAi7utl8DPDW6iJKks9Gn6DcAxwf2Z7uxQb8NfCDJLPNn8x8ZmNvcPaXzl0l+ZrFvkGRXkukk03Nzc/3TS5KGGtXF2BuAO6tqI3Ad8PkkPwI8Dby5qq4EfhP4wyQXLzy4qvZW1WRVTU5MTIwokiQJ+hX9CWDTwP7GbmzQB4G7AarqYeAiYH1Vfa+q/rEbfxR4Enjr2YaWJPXXp+gPAluSbE5yAbATmFqw5u+AdwAkuZz5op9LMtFdzCXJW4AtwLFRhZckDTf0VTdVdTLJTcC9wBpgX1UdTrIHmK6qKeC3gD9I8lHmL8z+alVVkp8F9iT5PvAi8KGqenbFfhpJ0ssMLXqAqjrA/EXWwbFPDmwfAa5a5Lg/Bv74LDNKks6C74yVpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mN61X0SbYnOZpkJsnuRebfnOTBJF9LcijJdQNzH++OO5rkXaMML0kabu2wBUnWALcB1wKzwMEkU1V1ZGDZJ4C7q+r2JFuBA8Cl3fZO4CeANwFfSfLWqnph1D+IJGlxfc7otwEzVXWsqp4H9gM7Fqwp4OJu+zXAU932DmB/VX2vqv4XMNPdnyRplfQp+g3A8YH92W5s0G8DH0gyy/zZ/EeWcSxJdiWZTjI9NzfXM7okqY9RXYy9AbizqjYC1wGfT9L7vqtqb1VNVtXkxMTEiCJJkqDHc/TACWDTwP7GbmzQB4HtAFX1cJKLgPU9j5UkraA+Z90HgS1JNie5gPmLq1ML1vwd8A6AJJcDFwFz3bqdSS5MshnYAvzVqMJLkoYbekZfVSeT3ATcC6wB9lXV4SR7gOmqmgJ+C/iDJB9l/sLsr1ZVAYeT3A0cAU4CH/YVN5K0uvo8dUNVHWD+Iuvg2CcHto8AVy1x7KeAT51FRknSWfCdsZLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXG9ij7J9iRHk8wk2b3I/H9O8lh3ezzJtwfmXhiYmxpleEnScGuHLUiyBrgNuBaYBQ4mmaqqI6fWVNVHB9Z/BLhy4C6eq6orRhdZkrQcfc7otwEzVXWsqp4H9gM7TrP+BuALowgnSTp7Q8/ogQ3A8YH9WeDtiy1McgmwGXhgYPiiJNPASeDWqvrTRY7bBezqdv9vkqM9cq2E9cA/jOl7n43zMff5mBnMvZrOx8xwFrnz6bP6vpcsNdGn6JdjJ3BPVb0w+M2r6kSStwAPJPmbqnpy8KCq2gvsHXGWZUsyXVWT486xXOdj7vMxM5h7NZ2PmeHczN3nqZsTwKaB/Y3d2GJ2suBpm6o60X09BjzES5+/lyStsD5FfxDYkmRzkguYL/OXvXomyWXAOuDhgbF1SS7sttcDVwFHFh4rSVo5Q5+6qaqTSW4C7gXWAPuq6nCSPcB0VZ0q/Z3A/qqqgcMvBz6b5EXmH1RuHXy1zjlo7E8fnaHzMff5mBnMvZrOx8xwDubOS3tZktQa3xkrSY2z6CWpca/ook/yuiT3JXmi+7pukTWXJPnr7iMcDif50DiyLsjUJ/cVSR7uMh9K8kvjyDqQZ2jmbt1fJPl2ki+tdsYFOYZ97MeFSb7Yzf/PJJeufsqXZRqW+We73+WTSd43joyL6ZH7N5Mc6X6P7+/erzN2PXJ/KMnfdN3x35NsHUdOAKrqFXsD/hOwu9veDXx6kTUXABd22/8K+CbwpvMg91uBLd32m4Cngdeey5m7uXcAvwB8aYxZ1wBPAm/p/v+/DmxdsOY/And02zuBL475d6JP5kuBtwF3Ae8bZ95l5v53wL/stv/DuP+tl5H74oHt64G/GFfeV/QZPfMf5fC5bvtzwHsWLqiq56vqe93uhZwbfwX1yf14VT3RbT8FPANMrFrClxuaGaCq7gf+z2qFWkKfj/0Y/HnuAd6RJKuYcaGhmavqm1V1CHhxHAGX0Cf3g1X13W73EebfyzNufXL/88Duq4GxvfLlXCitcXpDVT3dbf898IbFFiXZlOQQ8x8F8emuOMepV+5Tkmxj/qzjydOtW2HLyjxmi33sx4al1lTVSeA7wOtXJd3i+mQ+Fy039weBP1/RRP30yp3kw0meZP4v2l9fpWwvM+qPQDjnJPkK8GOLTN08uFNVlWTRR9yqOg68LcmbgD9Nck9VfWv0aX9oFLm7+3kj8Hngxqpa0TO5UWWWFpPkA8AkcPW4s/RVVbcBtyV5P/AJ4MZx5Gi+6Kvq55aaS/KtJG+sqqe7QnxmyH09leQbwM8w/+f6ihlF7iQXA18Gbq6qR1Yo6g+M8t96zPp87MepNbNJ1gKvAf5xdeItajkfVXIu6ZU7yc8xf8Jw9cBTqeO03H/v/cDtK5roNF7pT91M8cNH2BuBP1u4IMnGJP+i214H/FtgXJ+ueUqf3BcAfwLcVVUr+qDU09DM55A+H/sx+PO8D3iguqtuY9Lro0rOQUNzJ7kS+CxwfVWdKycIfXJvGdj9eeCJVcz3UuO+ej3OG/PPqd7f/Qd8BXhdNz4J/Ndu+1rgEPNX1Q8Bu86T3B8Avg88NnC74lzO3O3/N2AOeI755z3fNaa81wGPM39d4+ZubA/zZQNwEfBHwAzwV8BbzoHfi2GZf6r7N/1/zP/1cXjcmXvm/grwrYHf46lxZ+6Z+78Ah7vMDwI/Ma6sfgSCJDXulf7UjSQ1z6KXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9Jjfv/9dBpvOHm0usAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etPyqsjns9YN",
        "outputId": "eb8d52f8-4536-4264-ae1b-45c3f463438e"
      },
      "source": [
        "print()\n",
        "print(\"Execution Time %s seconds: \" % (time.time() - start_time)) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution Time 281.028520822525 seconds: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TLGhOaVHs_4i",
        "outputId": "3df55497-f528-4c0a-dd2c-b0d3abea410f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_data = pd.read_excel('wine_excel.xlsx', header=None)\n",
        "test_data = test_data.transpose()   #### Transposing the excel data\n",
        "\n",
        "test_data"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Attribute\\Wine sample</td>\n",
              "      <td>Alcohol</td>\n",
              "      <td>Malic acid</td>\n",
              "      <td>Ash</td>\n",
              "      <td>Alcalinity of ash</td>\n",
              "      <td>Magnesium</td>\n",
              "      <td>Total phenols</td>\n",
              "      <td>Flavanoids</td>\n",
              "      <td>Nonflavanoid phenols</td>\n",
              "      <td>Proanthocyanins</td>\n",
              "      <td>Color intensity</td>\n",
              "      <td>Hue</td>\n",
              "      <td>OD280/OD315 of diluted wines</td>\n",
              "      <td>Proline</td>\n",
              "      <td>CAT PREDICTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11.4722</td>\n",
              "      <td>3.83219</td>\n",
              "      <td>2.25229</td>\n",
              "      <td>10.1414</td>\n",
              "      <td>114.437</td>\n",
              "      <td>2.29147</td>\n",
              "      <td>2.16888</td>\n",
              "      <td>2.53561</td>\n",
              "      <td>1.43301</td>\n",
              "      <td>6.93169</td>\n",
              "      <td>1.37229</td>\n",
              "      <td>2.1376</td>\n",
              "      <td>745.92</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>11.2252</td>\n",
              "      <td>2.19536</td>\n",
              "      <td>2.18777</td>\n",
              "      <td>12.121</td>\n",
              "      <td>105.547</td>\n",
              "      <td>2.58447</td>\n",
              "      <td>2.00736</td>\n",
              "      <td>2.56314</td>\n",
              "      <td>1.86205</td>\n",
              "      <td>6.59835</td>\n",
              "      <td>1.2353</td>\n",
              "      <td>2.8443</td>\n",
              "      <td>1027.81</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12.1945</td>\n",
              "      <td>1.61397</td>\n",
              "      <td>2.54119</td>\n",
              "      <td>10.3771</td>\n",
              "      <td>111.963</td>\n",
              "      <td>2.32897</td>\n",
              "      <td>2.32306</td>\n",
              "      <td>2.32061</td>\n",
              "      <td>1.09417</td>\n",
              "      <td>6.5043</td>\n",
              "      <td>2.5581</td>\n",
              "      <td>2.58015</td>\n",
              "      <td>692.632</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>11.5614</td>\n",
              "      <td>2.43352</td>\n",
              "      <td>2.10456</td>\n",
              "      <td>17.2986</td>\n",
              "      <td>110.329</td>\n",
              "      <td>2.236</td>\n",
              "      <td>2.19247</td>\n",
              "      <td>2.33303</td>\n",
              "      <td>1.65863</td>\n",
              "      <td>6.52543</td>\n",
              "      <td>2.25187</td>\n",
              "      <td>3.1275</td>\n",
              "      <td>1197.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11.3208</td>\n",
              "      <td>2.62838</td>\n",
              "      <td>2.08426</td>\n",
              "      <td>18.2672</td>\n",
              "      <td>107.554</td>\n",
              "      <td>2.03639</td>\n",
              "      <td>2.01833</td>\n",
              "      <td>2.9601</td>\n",
              "      <td>1.76101</td>\n",
              "      <td>6.30784</td>\n",
              "      <td>1.03513</td>\n",
              "      <td>3.31129</td>\n",
              "      <td>1501.18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>10.79</td>\n",
              "      <td>2.02949</td>\n",
              "      <td>2.59952</td>\n",
              "      <td>14.0883</td>\n",
              "      <td>100.865</td>\n",
              "      <td>2.78794</td>\n",
              "      <td>2.73867</td>\n",
              "      <td>2.35793</td>\n",
              "      <td>1.29711</td>\n",
              "      <td>6.04752</td>\n",
              "      <td>2.72767</td>\n",
              "      <td>2.95164</td>\n",
              "      <td>1228.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>11.3142</td>\n",
              "      <td>2.92099</td>\n",
              "      <td>2.2644</td>\n",
              "      <td>11.3131</td>\n",
              "      <td>105.672</td>\n",
              "      <td>2.52932</td>\n",
              "      <td>2.77085</td>\n",
              "      <td>2.47529</td>\n",
              "      <td>1.50477</td>\n",
              "      <td>6.77992</td>\n",
              "      <td>2.85008</td>\n",
              "      <td>3.51537</td>\n",
              "      <td>673.36</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>10.6586</td>\n",
              "      <td>2.08104</td>\n",
              "      <td>2.97305</td>\n",
              "      <td>8.45198</td>\n",
              "      <td>107.906</td>\n",
              "      <td>2.57738</td>\n",
              "      <td>2.75875</td>\n",
              "      <td>2.56783</td>\n",
              "      <td>1.21569</td>\n",
              "      <td>6.49748</td>\n",
              "      <td>1.29151</td>\n",
              "      <td>2.0144</td>\n",
              "      <td>1304.38</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>13.4488</td>\n",
              "      <td>1.17771</td>\n",
              "      <td>2.28377</td>\n",
              "      <td>13.7642</td>\n",
              "      <td>107.261</td>\n",
              "      <td>2.16304</td>\n",
              "      <td>2.81686</td>\n",
              "      <td>2.41259</td>\n",
              "      <td>1.30511</td>\n",
              "      <td>6.90504</td>\n",
              "      <td>1.88018</td>\n",
              "      <td>3.39265</td>\n",
              "      <td>717.438</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>13.2953</td>\n",
              "      <td>3.75582</td>\n",
              "      <td>2.57619</td>\n",
              "      <td>15.8314</td>\n",
              "      <td>112.943</td>\n",
              "      <td>2.27918</td>\n",
              "      <td>2.01072</td>\n",
              "      <td>2.82335</td>\n",
              "      <td>1.65194</td>\n",
              "      <td>6.91291</td>\n",
              "      <td>2.67268</td>\n",
              "      <td>2.01962</td>\n",
              "      <td>1366.07</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       0        1   ...       13              14\n",
              "0   Attribute\\Wine sample  Alcohol  ...  Proline  CAT PREDICTION\n",
              "1                       1  11.4722  ...   745.92             NaN\n",
              "2                       2  11.2252  ...  1027.81             NaN\n",
              "3                       3  12.1945  ...  692.632             NaN\n",
              "4                       4  11.5614  ...   1197.8             NaN\n",
              "5                       5  11.3208  ...  1501.18             NaN\n",
              "6                       6    10.79  ...   1228.6             NaN\n",
              "7                       7  11.3142  ...   673.36             NaN\n",
              "8                       8  10.6586  ...  1304.38             NaN\n",
              "9                       9  13.4488  ...  717.438             NaN\n",
              "10                     10  13.2953  ...  1366.07             NaN\n",
              "\n",
              "[11 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ncBq_GcFthyu",
        "outputId": "8c90ce66-50e9-4569-89f7-2937c601eb17"
      },
      "source": [
        "test_data = test_data.drop(0, 1)  ### Drop the Attribute\\Wine sample \n",
        "test_data = test_data.drop(14, 1)   ### Drop the last column. \n",
        "test_data  #### 10 samples with feature values"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alcohol</td>\n",
              "      <td>Malic acid</td>\n",
              "      <td>Ash</td>\n",
              "      <td>Alcalinity of ash</td>\n",
              "      <td>Magnesium</td>\n",
              "      <td>Total phenols</td>\n",
              "      <td>Flavanoids</td>\n",
              "      <td>Nonflavanoid phenols</td>\n",
              "      <td>Proanthocyanins</td>\n",
              "      <td>Color intensity</td>\n",
              "      <td>Hue</td>\n",
              "      <td>OD280/OD315 of diluted wines</td>\n",
              "      <td>Proline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.4722</td>\n",
              "      <td>3.83219</td>\n",
              "      <td>2.25229</td>\n",
              "      <td>10.1414</td>\n",
              "      <td>114.437</td>\n",
              "      <td>2.29147</td>\n",
              "      <td>2.16888</td>\n",
              "      <td>2.53561</td>\n",
              "      <td>1.43301</td>\n",
              "      <td>6.93169</td>\n",
              "      <td>1.37229</td>\n",
              "      <td>2.1376</td>\n",
              "      <td>745.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.2252</td>\n",
              "      <td>2.19536</td>\n",
              "      <td>2.18777</td>\n",
              "      <td>12.121</td>\n",
              "      <td>105.547</td>\n",
              "      <td>2.58447</td>\n",
              "      <td>2.00736</td>\n",
              "      <td>2.56314</td>\n",
              "      <td>1.86205</td>\n",
              "      <td>6.59835</td>\n",
              "      <td>1.2353</td>\n",
              "      <td>2.8443</td>\n",
              "      <td>1027.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.1945</td>\n",
              "      <td>1.61397</td>\n",
              "      <td>2.54119</td>\n",
              "      <td>10.3771</td>\n",
              "      <td>111.963</td>\n",
              "      <td>2.32897</td>\n",
              "      <td>2.32306</td>\n",
              "      <td>2.32061</td>\n",
              "      <td>1.09417</td>\n",
              "      <td>6.5043</td>\n",
              "      <td>2.5581</td>\n",
              "      <td>2.58015</td>\n",
              "      <td>692.632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.5614</td>\n",
              "      <td>2.43352</td>\n",
              "      <td>2.10456</td>\n",
              "      <td>17.2986</td>\n",
              "      <td>110.329</td>\n",
              "      <td>2.236</td>\n",
              "      <td>2.19247</td>\n",
              "      <td>2.33303</td>\n",
              "      <td>1.65863</td>\n",
              "      <td>6.52543</td>\n",
              "      <td>2.25187</td>\n",
              "      <td>3.1275</td>\n",
              "      <td>1197.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11.3208</td>\n",
              "      <td>2.62838</td>\n",
              "      <td>2.08426</td>\n",
              "      <td>18.2672</td>\n",
              "      <td>107.554</td>\n",
              "      <td>2.03639</td>\n",
              "      <td>2.01833</td>\n",
              "      <td>2.9601</td>\n",
              "      <td>1.76101</td>\n",
              "      <td>6.30784</td>\n",
              "      <td>1.03513</td>\n",
              "      <td>3.31129</td>\n",
              "      <td>1501.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10.79</td>\n",
              "      <td>2.02949</td>\n",
              "      <td>2.59952</td>\n",
              "      <td>14.0883</td>\n",
              "      <td>100.865</td>\n",
              "      <td>2.78794</td>\n",
              "      <td>2.73867</td>\n",
              "      <td>2.35793</td>\n",
              "      <td>1.29711</td>\n",
              "      <td>6.04752</td>\n",
              "      <td>2.72767</td>\n",
              "      <td>2.95164</td>\n",
              "      <td>1228.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11.3142</td>\n",
              "      <td>2.92099</td>\n",
              "      <td>2.2644</td>\n",
              "      <td>11.3131</td>\n",
              "      <td>105.672</td>\n",
              "      <td>2.52932</td>\n",
              "      <td>2.77085</td>\n",
              "      <td>2.47529</td>\n",
              "      <td>1.50477</td>\n",
              "      <td>6.77992</td>\n",
              "      <td>2.85008</td>\n",
              "      <td>3.51537</td>\n",
              "      <td>673.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10.6586</td>\n",
              "      <td>2.08104</td>\n",
              "      <td>2.97305</td>\n",
              "      <td>8.45198</td>\n",
              "      <td>107.906</td>\n",
              "      <td>2.57738</td>\n",
              "      <td>2.75875</td>\n",
              "      <td>2.56783</td>\n",
              "      <td>1.21569</td>\n",
              "      <td>6.49748</td>\n",
              "      <td>1.29151</td>\n",
              "      <td>2.0144</td>\n",
              "      <td>1304.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13.4488</td>\n",
              "      <td>1.17771</td>\n",
              "      <td>2.28377</td>\n",
              "      <td>13.7642</td>\n",
              "      <td>107.261</td>\n",
              "      <td>2.16304</td>\n",
              "      <td>2.81686</td>\n",
              "      <td>2.41259</td>\n",
              "      <td>1.30511</td>\n",
              "      <td>6.90504</td>\n",
              "      <td>1.88018</td>\n",
              "      <td>3.39265</td>\n",
              "      <td>717.438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13.2953</td>\n",
              "      <td>3.75582</td>\n",
              "      <td>2.57619</td>\n",
              "      <td>15.8314</td>\n",
              "      <td>112.943</td>\n",
              "      <td>2.27918</td>\n",
              "      <td>2.01072</td>\n",
              "      <td>2.82335</td>\n",
              "      <td>1.65194</td>\n",
              "      <td>6.91291</td>\n",
              "      <td>2.67268</td>\n",
              "      <td>2.01962</td>\n",
              "      <td>1366.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         1           2   ...                            12       13\n",
              "0   Alcohol  Malic acid  ...  OD280/OD315 of diluted wines  Proline\n",
              "1   11.4722     3.83219  ...                        2.1376   745.92\n",
              "2   11.2252     2.19536  ...                        2.8443  1027.81\n",
              "3   12.1945     1.61397  ...                       2.58015  692.632\n",
              "4   11.5614     2.43352  ...                        3.1275   1197.8\n",
              "5   11.3208     2.62838  ...                       3.31129  1501.18\n",
              "6     10.79     2.02949  ...                       2.95164   1228.6\n",
              "7   11.3142     2.92099  ...                       3.51537   673.36\n",
              "8   10.6586     2.08104  ...                        2.0144  1304.38\n",
              "9   13.4488     1.17771  ...                       3.39265  717.438\n",
              "10  13.2953     3.75582  ...                       2.01962  1366.07\n",
              "\n",
              "[11 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ErnIYAZtl1Y"
      },
      "source": [
        "test_data = test_data.drop(labels=[0], axis=0)  #### dropping the header"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_aWdYjZtpMI"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5roBJG-tra0"
      },
      "source": [
        "test_data = np.asarray(test_data).astype(np.float32)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amqRdaRXtu7J"
      },
      "source": [
        "#from sklearn.preprocessing import StandardScaler\n",
        "#sc = StandardScaler(with_mean=True, with_std=True)\n",
        "#sc.fit(X_train)\n",
        "test_data = sc.transform(test_data) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exZe7Nz4tx3N",
        "outputId": "2477eaaf-7919-4f76-d4ed-f5f7fadb9b72"
      },
      "source": [
        "predictions = model.predict(test_data)     #### Predict using the trained model \n",
        "print(predictions)    \n",
        "y_classes = predictions.argmax(axis=-1)\n",
        "y_classes \n",
        "i = 1\n",
        "for x in y_classes:\n",
        "  print('For sample %d , the class is %s ' % (i, x))      #### printing the classes \n",
        "  #print (\"Sample %i predicted class is {} \" % (i,x))\n",
        "\n",
        "  i =i +1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02529438 0.907543   0.06716266]\n",
            " [0.02733117 0.89614606 0.0765227 ]\n",
            " [0.07597607 0.90478724 0.01923661]\n",
            " [0.05502183 0.91894925 0.02602889]\n",
            " [0.01282273 0.9213169  0.06586041]\n",
            " [0.08187771 0.90721923 0.01090307]\n",
            " [0.05536588 0.93670684 0.00792721]\n",
            " [0.03389404 0.90657926 0.05952663]\n",
            " [0.05511729 0.8992683  0.04561444]\n",
            " [0.0498189  0.9349252  0.0152559 ]]\n",
            "For sample 1 , the class is 1 \n",
            "For sample 2 , the class is 1 \n",
            "For sample 3 , the class is 1 \n",
            "For sample 4 , the class is 1 \n",
            "For sample 5 , the class is 1 \n",
            "For sample 6 , the class is 1 \n",
            "For sample 7 , the class is 1 \n",
            "For sample 8 , the class is 1 \n",
            "For sample 9 , the class is 1 \n",
            "For sample 10 , the class is 1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgBF2Q9ut18q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}